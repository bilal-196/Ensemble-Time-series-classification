{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessarily libraries \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyts.approximation import SymbolicAggregateApproximation, SymbolicFourierApproximation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyts.preprocessing import StandardScaler\n",
    "import random\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import BorderlineSMOTE, SMOTE\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import heapq\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions required for Co-eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the most confident label across lenses in one representation (either SAX or SFA)\n",
    "def mostConf_one(matrcies, labels):\n",
    "    #Marerices is of length L: number of lenses/forests\n",
    "    #Each matrix in matrices is the probalistic accuracy of test data \n",
    "    #Matrix of size m X n: where m is the number of test instances,n is the number of classes  \n",
    "    predLabels=[]\n",
    "    # For each test data\n",
    "    for row in range(len(matrcies[0])):\n",
    "        maxConf= 0\n",
    "    # For each Forest/lense\n",
    "        for mat in matrcies: \n",
    "            for col in range(len(labels)):\n",
    "                if(mat[row][col]>maxConf):\n",
    "                    maxConf= mat[row][col]\n",
    "                    Conflabel= labels[col]    \n",
    "        #Return the most confident lable across lenses \n",
    "        predLabels.append(Conflabel)\n",
    "    return predLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Vote function described in Section 4.3 in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Find the most confident labeles across lenses of the two representations ( SAX and SFA)\n",
    "\n",
    "def mostConf_multi(matrcies, labels, sfa_n):\n",
    "    #Marerices is of length L: number of lenses/forests (total for SAX and SFA)\n",
    "    #Each matrix in matrices is the probalistic accuracy of test data \n",
    "    #Matrix of size m X n: where m is the number of test instances,n is the number of classes (labels)\n",
    "    #Sax_n number of lenses in SFA\n",
    "    \n",
    "    predLabel=[]\n",
    "    multiSFA = False\n",
    "    multiSAX= False\n",
    "    \n",
    "    # For each test data, we define the most confident and second-most confident for each presentation, then vote between them\n",
    "    for row in range(len(matrcies[0])):\n",
    "        #Initialise\n",
    "        maxConf_SFA= 0\n",
    "        SFAConf=[]\n",
    "        SFALables= []\n",
    "        SAXConf=[]\n",
    "        SAXLables= []\n",
    "        #Look into SFA only matrices\n",
    "        #Find the max confidence/ prbability in SFA\n",
    "        for mat in matrcies[:sfa_n]: \n",
    "            for col in range(len(labels)):\n",
    "                SFAConf.append(mat[row][col])\n",
    "                SFALables.append(labels[col])\n",
    "                if(mat[row][col]>maxConf_SFA):\n",
    "                    maxConf_SFA= mat[row][col]\n",
    "                    Conflabel_SFA= labels[col]\n",
    "        \n",
    "        #Second best flag\n",
    "        SB1= False\n",
    "        #Special case: when multiple lenses have the same accuracy (most confident)\n",
    "        if(SFAConf.count(maxConf_SFA)>1): \n",
    "            indices = [i for i, x in enumerate(SFAConf) if x == maxConf_SFA]                \n",
    "            l= [SFALables[i] for i in indices]\n",
    "            if(len(set(l))!=1): \n",
    "                maxIr=max(l.count(y) for y in set(l))\n",
    "                k= [l.count(y) for y in set(l)]\n",
    "                        \n",
    "                # Find the most common label\n",
    "                if(k.count (maxIr)==1): \n",
    "                    cnt = Counter(l)\n",
    "                    Conflabel_SFA= cnt.most_common(2)[0][0] \n",
    "                    secondBestSFALabel= cnt.most_common(2)[1][0] \n",
    "               \n",
    "            #If no common label, in case of tie, the label is chosen randomly.\n",
    "                else: \n",
    "                    shuff=[]\n",
    "                    for it in set(l): \n",
    "                        if (l.count(it)==maxIr): shuff.append(it)\n",
    "                    shuff= list(set(l))\n",
    "                    random.shuffle(shuff)\n",
    "                    Conflabel_SFA= shuff[0]\n",
    "                    secondBestSFALabel= shuff[1]\n",
    "                SB1= True\n",
    "                #Set the second best \n",
    "                secondBestSFA= maxConf_SFA\n",
    "        \n",
    "        if(SB1== False):\n",
    "            secondBestSFA=  max(n for n in SFAConf if n!=maxConf_SFA)      \n",
    "            secondBestSFALabel=  SFALables[SFAConf.index(secondBestSFA)]\n",
    "        \n",
    "        #Same steps for SAX\n",
    "        maxConf_SAX= 0\n",
    "        SB2= False\n",
    "        for mat in matrcies[sfa_n:]: \n",
    "            for col in range(len(labels)):\n",
    "                SAXConf.append(mat[row][col])\n",
    "                SAXLables.append(labels[col])\n",
    "                if(mat[row][col]>maxConf_SAX):    \n",
    "                    maxConf_SAX= mat[row][col]\n",
    "                    Conflabel_SAX= labels[col]\n",
    "        if(SAXConf.count(maxConf_SAX)>1): \n",
    "            indices = [i for i, x in enumerate(SAXConf) if x == maxConf_SAX]                \n",
    "            l= [SAXLables[i] for i in indices]\n",
    "            if(len(set(l))!=1): \n",
    "                print (\"Conflict on max confident\", l) \n",
    "                maxIr=max(l.count(y) for y in set(l))\n",
    "                k= [l.count(y) for y in set(l)]\n",
    "#                 How many equal items with max confident value  \n",
    "                if(k.count (maxIr)==1):  \n",
    "                    cnt = Counter(l)\n",
    "                    Conflabel_SAX= cnt.most_common(2)[0][0] \n",
    "                    secondBestSAXLabel= cnt.most_common(2)[1][0] \n",
    "                else:\n",
    "                    shuff=[]\n",
    "                    for it in set(l): \n",
    "                        if (l.count(it)==maxIr): shuff.append(it)\n",
    "                    print (\"tie\", shuff)\n",
    "                    random.shuffle(shuff)\n",
    "                    Conflabel_SAX= shuff[0]\n",
    "                    secondBestSAXLabel= shuff[1]\n",
    "                   \n",
    "                secondBestSAX= maxConf_SAX\n",
    "#                 print(\"most common\", Conflabel_SAX, \"Second Best\", secondBestSAXLabel)\n",
    "                SB2= True\n",
    "#             print(\"indecies\", indices, \"labels\" ,labels)\n",
    "        if(SB2== False):\n",
    "            secondBestSAX=  max(n for n in SAXConf if n!=maxConf_SAX)      \n",
    "            secondBestSAXLabel=  SAXLables[SAXConf.index(secondBestSAX)]\n",
    "        \n",
    "#         print (\"Best SAX\",maxConf_SAX , Conflabel_SAX)    \n",
    "#         print (\"Second Best SAX\",secondBestSAX , secondBestSAXLabel)    \n",
    "        \n",
    "   #-----------------------------------\n",
    "        # In case of agreement between most Conf SAX and SFA\n",
    "        if(Conflabel_SAX==Conflabel_SFA): \n",
    "            best= Conflabel_SAX\n",
    "        # If no agreement, then second best is testes\n",
    "        elif(secondBestSAX>secondBestSFA): best= secondBestSAXLabel\n",
    "        else: best= secondBestSFALabel\n",
    "        #Accumulate labels with the best choice\n",
    "        predLabel.append(best)\n",
    "#         print(\"Best SFA, SAX\", Conflabel_SAX, Conflabel_SFA,\"Second best SFA, SAX\", secondBestSAXLabel, secondBestSFALabel,\"Best\",  best)\n",
    "#         print (\"----------------------------------------\")\n",
    "\n",
    "    return predLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### searchLenses [Algorithm 2 (Co-eye paper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding best pairs for SFA transformation \n",
    "def searchLense_SFA(X_train, y_train): \n",
    "    #Input is training data (X_train, y_train)\n",
    "    #Returns selected pairs for SFA transformation based on cross validation\n",
    "   \n",
    "    #Set ranges (Seg, alpha) parameters\n",
    "    print(\"Generating SFA parameters....\")\n",
    "    maxCoof= 130\n",
    "    if(X_train.shape[1]<maxCoof): maxCoof = X_train.shape[1]-1\n",
    "    if(X_train.shape[1]<100): n_segments=list(range(5, maxCoof,5))\n",
    "    else: n_segments=list(range(10, maxCoof,10))\n",
    "    \n",
    "    maxBin= 26\n",
    "    if(X_train.shape[1]<maxBin): maxBin = X_train.shape[1]-2\n",
    "    if(X_train.shape[0]<maxBin): maxBin = X_train.shape[0]-2\n",
    "    alphas= range(3,maxBin)\n",
    "    \n",
    "    pairs= []\n",
    "\n",
    "    # Learning parameteres using 5 folds cross validation\n",
    "\n",
    "    for alpha in alphas: \n",
    "        s= []\n",
    "        for seg in n_segments:  \n",
    "            SFA= SymbolicFourierApproximation( n_coefs=seg, n_bins= alpha, alphabet= 'ordinal')\n",
    "            X_SFA = SFA.fit_transform(X_train)        \n",
    "            scores= 0\n",
    "            RF_clf= RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "            scores = cross_val_score(RF_clf, X_SFA, y_train, cv=5)  \n",
    "            s.append(scores.mean())\n",
    "        winner = np.argwhere(s >= np.amax(s)-0.01)\n",
    "        for i in winner.flatten().tolist(): \n",
    "            bestCof= n_segments[i]\n",
    "            pairs.append((bestCof, alpha)) \n",
    "    print(\"No of pairs generated: \", len(pairs))\n",
    "    print(\"SAX pamaeter selection, done!\")\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding best pairs for SAX transformation \n",
    "\n",
    "def searchLense_SAX(X_train, y_train): \n",
    "    #Input is training data (X_train, y_train)\n",
    "    #Returns selected pairs for SAX transformation based on cross validation    \n",
    "    \n",
    "    #Set range (alpha) parameter\n",
    "    print(\"Generating SAX parameters....\")\n",
    "\n",
    "    maxBin= 26\n",
    "    if(X_train.shape[1]<maxBin): maxBin = X_train.shape[1]\n",
    "    alphas= range(3,maxBin)\n",
    "    s= []\n",
    "    pairs= []\n",
    "\n",
    "    #Learning parameters using 5 folds cross validation\n",
    "    for alpha in alphas: \n",
    "        SAX = SymbolicAggregateApproximation(strategy= 'uniform', n_bins=alpha, alphabet= 'ordinal')\n",
    "        X_train_SAX = SAX.fit_transform(X_train)           \n",
    "        scores= 0\n",
    "        RF_clf= RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "        scores = cross_val_score(RF_clf, X_train_SAX, y_train, cv=5)  \n",
    "        s.append(scores.mean())\n",
    "    winner = np.argwhere(s >= np.mean(s)-0.01)\n",
    "    for i in winner.flatten().tolist(): \n",
    "        bestCof= alphas[i]\n",
    "        pairs.append(bestCof)    \n",
    "    \n",
    "    print(\"No of pairs generated: \", len(pairs))\n",
    "    print(\"SAX pamaeter selection, done!\")\n",
    "    \n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-eye Main Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------\n",
      "Dataset:  Coffee\n",
      "(28, 286) (28, 286) (28,) (28,)\n",
      "Class distribution  [(0, 14), (1, 14)]\n",
      "Data has equal distribution among classes \n",
      "Generating SFA parameters....\n",
      "No of pairs generated:  219\n",
      "done!\n",
      "\n",
      " SFA Correct classification rate: 1.0000  Error rate 0.0 219 \n",
      "\n",
      "Generating SAX parameters....\n",
      "No of pairs generated:  18\n",
      "done!\n",
      "\n",
      " SAX only Correct classification rate: 1.0000  Error rate 0.0  arr length 18\n",
      "\n",
      " Co-eye Correct classification rate: 1.0000  Error rate 0.0  arr length 237\n",
      " -----------------------------------------\n",
      "\n",
      "-------------------\n",
      "Dataset:  Beef\n",
      "(30, 470) (30, 470) (30,) (30,)\n",
      "Class distribution  [(1, 6), (2, 6), (3, 6), (4, 6), (5, 6)]\n",
      "Data has equal distribution among classes \n",
      "Generating SFA parameters....\n",
      "No of pairs generated:  36\n",
      "done!\n",
      "\n",
      " SFA Correct classification rate: 0.8333  Error rate 0.16666666666666663 36 \n",
      "\n",
      "Generating SAX parameters....\n",
      "No of pairs generated:  9\n",
      "done!\n",
      "\n",
      " SAX only Correct classification rate: 0.6000  Error rate 0.4  arr length 9\n",
      "Conflict on max confident [3, 2]\n",
      "tie [2, 3]\n",
      "Conflict on max confident [5, 2]\n",
      "tie [2, 5]\n",
      "\n",
      " Co-eye Correct classification rate: 0.7667  Error rate 0.23333333333333328  arr length 45\n",
      " -----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Main Run\n",
    "#Initialisation\n",
    "All_Acc=[]\n",
    "SFA_acc=[]\n",
    "SAX_acc=[]\n",
    "SFA_pairs= []\n",
    "SAX_pairs= []\n",
    "\n",
    "#List names of datasets to use/test\n",
    "files= ['Coffee', 'Beef']\n",
    "\n",
    "for f in files: \n",
    "    #Import and balance data \n",
    "    dirname = os.getcwd()\n",
    "    dftrain= pd.read_csv(dirname+'/UCR/'+f+'/'+f+'_TRAIN.tsv',header=None,  sep='\\t')\n",
    "    dftest= pd.read_csv(dirname+'/UCR/'+f+'/'+f+'_TEST.tsv',header=None,  sep='\\t')\n",
    "    print(\"\\n-------------------\\nDataset: \", f)\n",
    "    \n",
    "    #Split data to X_train, y_train and X_test, y_test\n",
    "    X_train= dftrain.drop([0], axis=1).values   \n",
    "    y_train= dftrain[0]\n",
    "    \n",
    "    X_test= dftest.drop([0], axis=1).values\n",
    "    y_test= dftest[0]\n",
    "    print ( X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    \n",
    "    #Check for class imbalance\n",
    "    print (\"Class distribution \",sorted(Counter(y_train).items()))\n",
    "    min_neighbours= min(Counter(y_train).items(), key=lambda k: k[1])[1]\n",
    "    max_neighbours= max(Counter(y_train).items(), key=lambda k: k[1])[1]\n",
    "    \n",
    "    \n",
    "    if(min_neighbours==max_neighbours): \n",
    "        print (\"Data has an equal distribution among classes \")\n",
    "        SMOTE_Xtrain= X_train\n",
    "        SMOTE_ytrain= y_train\n",
    "        \n",
    "    #Apply SMOTE if data is imbalanced\n",
    "    else:\n",
    "        if (min_neighbours>5): min_neighbours= 6\n",
    "        SMOTE_Xtrain, SMOTE_ytrain = SMOTE(sampling_strategy=\"all\", k_neighbors= min_neighbours-1, random_state=42).fit_resample(X_train, y_train )\n",
    "        print(\"Class distribution after balance\", sorted(Counter(SMOTE_ytrain).items()))\n",
    "        print(\"---------------------\")\n",
    "        print (\"After Balance\",  SMOTE_Xtrain.shape, X_test.shape, SMOTE_ytrain.shape, y_test.shape)\n",
    "    \n",
    "    #Initialise parameters for each dataset\n",
    "    #Random forest probability matrices for all lenses \n",
    "    RFmatrices= [] \n",
    "   \n",
    "\n",
    "    #Training Phase\n",
    "    #--------------\n",
    "    pairs= searchLense_SFA (SMOTE_Xtrain, SMOTE_ytrain)\n",
    "    for n_coefs, n_bins  in pairs: \n",
    "        SFA= SymbolicFourierApproximation( n_coefs=n_coefs, n_bins= n_bins, alphabet= 'ordinal')\n",
    "        #Transform to SFA\n",
    "        X_train_SFA = SFA.fit_transform(SMOTE_Xtrain)\n",
    "        X_test_SFA = SFA.fit_transform(X_test)\n",
    "        # Build RF on each lense\n",
    "        RF_clf= RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "        RF_clf.fit(X_train_SFA,SMOTE_ytrain)\n",
    "        #Store prediction probability for test data \n",
    "        model_pred=  RF_clf.predict_proba(X_test_SFA)\n",
    "        #accumulate RFmatrices for a lense\n",
    "        RFmatrices.append(model_pred)\n",
    "\n",
    "    \n",
    "    length= len(RFmatrices)\n",
    "    #Best probablistic accuracy using SFA only \n",
    "    acc= accuracy_score(y_test, mostConf_one(RFmatrices,RF_clf.classes_))\n",
    "    SFA_acc.append(acc)\n",
    "    SFA_pairs.append(length)\n",
    "    print(\"\\n *SFA Correct classification rate: {:2.4f} \".format(acc), \"Error rate\", 1-acc , length, \"\\n\")\n",
    "    \n",
    "    SAXacc=[]\n",
    "    # Transform to SAX Lenses\n",
    "\n",
    "    saxPairs= searchLense_SAX(SMOTE_Xtrain, SMOTE_ytrain)\n",
    "    for n_bins in saxPairs:\n",
    "        sax = SymbolicAggregateApproximation(strategy= 'uniform', n_bins=n_bins, alphabet= 'ordinal')\n",
    "        #Transform to SAX\n",
    "        X_sax = sax.fit_transform(SMOTE_Xtrain)\n",
    "        X_test_sax = sax.fit_transform(X_test)\n",
    "        #Build RF for each SAX lense\n",
    "        RF_clf= RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "        RF_clf.fit(X_sax,SMOTE_ytrain)\n",
    "        #Store prediction probability for test data \n",
    "        model_pred= RF_clf.predict_proba(X_test_sax)\n",
    "        #Sax only lenses\n",
    "        SAXacc.append(model_pred)\n",
    "        #accumulate RFmatrices for all lenses\n",
    "        RFmatrices.append(model_pred)\n",
    "        \n",
    "    #Classification Phase\n",
    "    #---------\n",
    "    saxAcc= accuracy_score(y_test, mostConf_one(SAXacc,RF_clf.classes_))\n",
    "    SAX_acc.append(saxAcc)\n",
    "    SAX_pairs.append(len(SAXacc))\n",
    "    print(\"\\n *SAX only Correct classification rate: {:2.4f} \".format(saxAcc), \"Error rate\", 1-saxAcc, \" arr length\", len(SAXacc))\n",
    "\n",
    "    #Combining both SAX and SFA using mostConf_multi method\n",
    "    acc= accuracy_score(y_test, mostConf_multi(RFmatrices,RF_clf.classes_,length))\n",
    "    print(\"\\n Co-eye Correct classification rate: {:2.4f} \".format(acc), \"Error rate\", 1-acc, \" arr length\", len(RFmatrices))\n",
    "    print(\" -----------------------------------------\")\n",
    "    All_Acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
